# Ensemble Methods - Jupyter Notebook

## Environment Used
- **Jupyter Notebook**

## Packages Used
The following Python libraries are required to run this notebook:
- `pandas` - Data manipulation and analysis
- `numpy` - Numerical computing
- `scikit-learn` - Machine learning models and preprocessing
- `autoviz` - Automated data visualization
- `xgboost` - Extreme Gradient Boosting (XGBoost) implementation
- `sklearn.ensemble` - Ensemble methods such as Random Forest, AdaBoost, and Gradient Boosting

## Data
The dataset used in this notebook can be found at the following link:  
[Download census_data.csv](https://github.com/ArinB/MSBA-CA-03-Decision-Trees/blob/master/census_data.csv?raw=true)

## Explanation of Assignment
This notebook explores various ensemble learning techniques for classification problems. The goal is to analyze and compare different ensemble methods to determine their effectiveness.

Key topics covered:
1. **Data Preprocessing**: Encoding categorical variables and preparing the dataset.
2. **Building Ensemble Models**:
   - Random Forest Classifier
   - AdaBoost Classifier
   - Gradient Boosting Classifier
   - XGBoost Classifier
3. **Hyperparameter Tuning**: Finding the optimal number of estimators for Random Forest.
4. **Performance Evaluation**: Comparing accuracy and AUC scores.

## Steps to Complete Assignment
To successfully complete this assignment, follow these steps:
1. Load the dataset and preprocess the features.
2. Train a Random Forest model and analyze its behavior with different numbers of estimators.
3. Implement AdaBoost, Gradient Boost, and XGBoost classifiers.
4. Evaluate models based on accuracy and AUC scores.
5. Document findings and observations regarding classifier performance.

